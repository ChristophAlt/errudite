{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "def import_sys():\n",
    "    import sys\n",
    "    sys.path.append('..')\n",
    "    sys.path.append('../..')\n",
    "import_sys()\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/tongshuangwu/sourcetree/errudite_dataset_debug/notebooks/caches/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n",
      "INFO:pytorch_pretrained_bert.modeling:Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n",
      "/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/sklearn/utils/linear_assignment_.py:21: DeprecationWarning: The linear_assignment_ module is deprecated in 0.21 and will be removed from 0.23. Use scipy.optimize.linear_sum_assignment instead.\n",
      "  DeprecationWarning)\n",
      "INFO:errudite.utils.file_utils:Errudite cache folder selected: /Users/tongshuangwu/datasets/caches/dataset_debug/mrqa-10\n",
      "INFO:errudite.io.dataset_reader:Reading instances from lines in file at: /Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/BioASQ.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/RACE.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/DROP.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/TextbookQA.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/RelationExtraction.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/DuoRC.jsonl.gz\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: BioASQ.\n",
      "0it [00:00, ?it/s]\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: RACE.\n",
      "0it [00:00, ?it/s]\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: DROP.\n",
      "0it [00:00, ?it/s]\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: TextbookQA.\n",
      "1it [00:00,  8.28it/s]\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: RelationExtraction.\n",
      "0it [00:00, ?it/s]\n",
      "INFO:errudite.io.mrqa_reader:Reading from dataset: DuoRC.ParaphraseRC.\n",
      "0it [00:00, ?it/s]\n",
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/tongshuangwu/datasets/caches/dataset_debug/mrqa-10/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n",
      "INFO:allennlp.models.archival:loading archive file /Users/tongshuangwu/datasets/models/mrqa/mrqa_bert_base.gz\n",
      "INFO:allennlp.models.archival:extracting archive file /Users/tongshuangwu/datasets/models/mrqa/mrqa_bert_base.gz to temp dir /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmpq_9q2zla\n",
      "INFO:allennlp.common.params:type = default\n",
      "INFO:allennlp.data.vocabulary:Loading token dictionary from /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmpq_9q2zla/vocabulary.\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.models.model.Model'> from params {'initializer': [], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}}, 'type': 'BERT_QA'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.type = BERT_QA\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'errudite.predictors.qa.mrqa_allennlp.BERT_QA.BERT_QA'> from params {'initializer': [], 'text_field_embedder': {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.text_field_embedders.text_field_embedder.TextFieldEmbedder'> from params {'allow_unmatched_keys': True, 'embedder_to_indexer_map': {'bert': ['bert', 'bert-offsets']}, 'token_embedders': {'bert': {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'}}} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.type = basic\n",
      "INFO:allennlp.common.params:model.text_field_embedder.allow_unmatched_keys = True\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.token_embedder.TokenEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': True, 'type': 'bert-pretrained'} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.type = bert-pretrained\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.modules.token_embedders.bert_token_embedder.PretrainedBertEmbedder'> from params {'pretrained_model': 'bert-base-uncased', 'requires_grad': True} and extras {'vocab'}\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.pretrained_model = bert-base-uncased\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.requires_grad = True\n",
      "INFO:allennlp.common.params:model.text_field_embedder.token_embedders.bert.top_layer_only = False\n",
      "INFO:pytorch_pretrained_bert.modeling:loading archive file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased.tar.gz from cache at /Users/tongshuangwu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba\n",
      "INFO:pytorch_pretrained_bert.modeling:extracting archive file /Users/tongshuangwu/.pytorch_pretrained_bert/9c41111e2de84547a463fd39217199738d1e3deb72d4fec4399e6e241983c6f0.ae3cef932725ca7a30cdcb93fc6e09150a55e2a130ec7af63975a16c153ae2ba to temp dir /var/folders/9k/yx4ryhp918qfxx59mmp174lh0000gn/T/tmpvofswr_f\n",
      "INFO:pytorch_pretrained_bert.modeling:Model config {\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "INFO:allennlp.common.params:model.initializer = []\n",
      "INFO:allennlp.common.params:model.dropout = 0.2\n",
      "INFO:allennlp.common.params:model.max_span_length = 30\n",
      "INFO:allennlp.common.params:model.predictions_file = None\n",
      "INFO:allennlp.common.params:model.use_multi_label_loss = False\n",
      "INFO:allennlp.common.params:model.stats_report_freq = None\n",
      "INFO:allennlp.common.params:model.debug_experiment_name = None\n",
      "INFO:allennlp.nn.initializers:Initializing parameters\n",
      "INFO:allennlp.nn.initializers:Done initializing parameters; the following parameters are using their default initialization from their code\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.gamma\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.0\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.1\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.10\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.11\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.2\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.3\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.4\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.5\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.6\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.7\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.8\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert._scalar_mix.scalar_parameters.9\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.embeddings.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.embeddings.position_embeddings.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.embeddings.token_type_embeddings.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.embeddings.word_embeddings.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.0.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.1.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.10.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.11.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.2.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.3.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.4.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.5.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.6.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.7.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.8.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.key.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.query.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.attention.self.value.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.intermediate.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.LayerNorm.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.encoder.layer.9.output.dense.weight\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.bias\n",
      "INFO:allennlp.nn.initializers:   _text_field_embedder.token_embedder_bert.bert_model.pooler.dense.weight\n",
      "INFO:allennlp.nn.initializers:   qa_outputs.bias\n",
      "INFO:allennlp.nn.initializers:   qa_outputs.weight\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'allennlp.data.dataset_readers.dataset_reader.DatasetReader'> from params {'is_training': True, 'lazy': True, 'sample_size': 75000, 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}, 'type': 'mrqa_reader'} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.type = mrqa_reader\n",
      "INFO:allennlp.common.from_params:instantiating class <class 'errudite.predictors.qa.mrqa_allennlp.mrqa_reader.MRQAReader'> from params {'is_training': True, 'lazy': True, 'sample_size': 75000, 'token_indexers': {'bert': {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True}}} and extras set()\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.token_indexer.TokenIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'type': 'bert-pretrained', 'use_starting_offsets': True} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.type = bert-pretrained\n",
      "INFO:allennlp.common.from_params:instantiating class allennlp.data.token_indexers.wordpiece_indexer.PretrainedBertIndexer from params {'do_lowercase': True, 'pretrained_model': 'bert-base-uncased', 'use_starting_offsets': True} and extras set()\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.pretrained_model = bert-base-uncased\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.use_starting_offsets = True\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.do_lowercase = True\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.never_lowercase = None\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.max_pieces = 512\n",
      "INFO:allennlp.common.params:dataset_reader.token_indexers.bert.truncate_long_sequences = True\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/tongshuangwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "INFO:allennlp.common.params:dataset_reader.dataset_weight = None\n",
      "INFO:allennlp.common.params:dataset_reader.lazy = True\n",
      "INFO:allennlp.common.params:dataset_reader.is_training = True\n",
      "INFO:allennlp.common.params:dataset_reader.sample_size = 75000\n",
      "INFO:allennlp.common.params:dataset_reader.STRIDE = 128\n",
      "INFO:allennlp.common.params:dataset_reader.MAX_WORDPIECES = 512\n",
      "INFO:pytorch_pretrained_bert.tokenization:loading vocabulary file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at /Users/tongshuangwu/.pytorch_pretrained_bert/26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n"
     ]
    }
   ],
   "source": [
    "import glob, os\n",
    "\n",
    "import errudite\n",
    "from errudite.io import DatasetReader\n",
    "from errudite.predictors import Predictor\n",
    "from errudite.targets.instance import Instance\n",
    "from errudite.targets.label import Label\n",
    "from errudite.utils import accuracy_score, normalize_file_path\n",
    "\n",
    "DATASET_FOLDER = normalize_file_path(\"~/datasets/raw_data/mrqa/out_of_domain_devs\")\n",
    "sample_size=10\n",
    "file_path = \",\".join(glob.glob(os.path.join(DATASET_FOLDER, \"*.jsonl.gz\")))\n",
    "reader = DatasetReader.by_name(\"mrqa\")(\n",
    "    cache_folder_path=f\"~/datasets/caches/dataset_debug/mrqa-{sample_size}\")\n",
    "instances = reader.read(file_path, sample_size=sample_size)\n",
    "\n",
    "MODEL_FOLDER = normalize_file_path(\"~/datasets/models/mrqa/\")\n",
    "predictor = Predictor.by_name(\"mrqa\")(\n",
    "    name=\"mrqa_path\", \n",
    "    model_path=os.path.join(MODEL_FOLDER, \"mrqa_bert_base.gz\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:__main__:Running predictions....\n",
      "  8%|▊         | 1/12 [00:00<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Neutrophil elastase gene (ELANE) mutations are responsible for the majority of cases of severe congenital neutropenia (CN) and cyclic neutropenia (CyN). We screened CN (n = 395) or CyN (n = 92) patients for ELANE mutations and investigated the impact of mutations on mRNA expression, protein expression, and activity. We found 116 different mutations in 162 (41%) CN patients and 26 in 51 (55%) CyN patients, 69 of them were novel. CyN-associated mutations were predicted to be more benign than CN-associated mutations, but the mutation severity largely overlapped. The frequency of acquired CSF3R mutations, malignant transformation, and the need for hematopoietic stem cell transplantation was significantly higher in CN patients with ELANE mutation than in ELANE mutation negative patients. Cellular elastase activity was reduced in neutrophils from CN/CyN patients, irrespective of the mutation status. In CN, enzymatic activity was significantly lower in patients with ELANE mutations compared with those with wild-type ELANE. Despite differences in the spectrum of mutations in CN or CyN, type or localization of mutation only partially determine the clinical phenotype. Specific ELANE mutations have limited predictive value for leukemogenesis; the risk for leukemia was correlated with disease severity rather than with occurrence of an ELANE mutation.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'elastase gene (ELANE', 'qid': 'tmp', 'best_span_logit': 9.327156066894531, 'char_offsets': [103, 123]}}\n",
      "elastase gene (ELANE 1 5 [Context] [ContextKey(aid='0', cid='BioASQ_0', vid=0, qid=None)]\n",
      "Neutrophil elastase gene (ELANE) mutations are responsible for the majority of cases of severe congenital neutropenia (CN) and cyclic neutropenia (CyN). We screened CN (n = 395) or CyN (n = 92) patients for ELANE mutations and investigated the impact of mutations on mRNA expression, protein expression, and activity. We found 116 different mutations in 162 (41%) CN patients and 26 in 51 (55%) CyN patients, 69 of them were novel. CyN-associated mutations were predicted to be more benign than CN-associated mutations, but the mutation severity largely overlapped. The frequency of acquired CSF3R mutations, malignant transformation, and the need for hematopoietic stem cell transplantation was significantly higher in CN patients with ELANE mutation than in ELANE mutation negative patients. Cellular elastase activity was reduced in neutrophils from CN/CyN patients, irrespective of the mutation status. In CN, enzymatic activity was significantly lower in patients with ELANE mutations compared with those with wild-type ELANE. Despite differences in the spectrum of mutations in CN or CyN, type or localization of mutation only partially determine the clinical phenotype. Specific ELANE mutations have limited predictive value for leukemogenesis; the risk for leukemia was correlated with disease severity rather than with occurrence of an ELANE mutation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 2/12 [00:01<00:07,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tardive dyskinesia (TD) is a movement disorder characterized by abnormal involuntary facial movements induced by chronic therapy with classical antipsychotic medications. Currently, there is no satisfactory pharmacotherapy for TD, which represents a major limitation to therapy with classical antipsychotics. In order to develop or optimize therapies for TD, and to develop new APDs with lower indices of motor side effects, the pathology underlying TD must first be understood. The use of animal models has been used to further this objective. Here, we review different preparations that have been used to model TD and discuss the contribution of neuroimaging studies conducted in these models. Studies in animal models have lead to several hypotheses of TD pathology, although none has yet emerged as the ultimate underlying cause of this syndrome. We discuss alterations in functional indices, neuron and synapse morphology and changes in specific neurotransmitter systems that have been described in animal models of TD, and outline how these findings have contributed to our understanding of antipsychotic-induced dyskinesias. We conclude that several non-mutually exclusive theories of TD are supported by animal studies, including increases in oxidative stress leading to structural and functional changes in specific neurotransmitter systems. Elucidating the mechanisms underlying TD neuropathology partly through the use of animal models will lead to the development of APDs with superior side effect profiles or more effective therapies for TD.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'abnormal involuntary facial movements', 'qid': 'tmp', 'best_span_logit': 4.974893569946289, 'char_offsets': [111, 148]}}\n",
      "abnormal involuntary facial movements 11 15 [Context] [ContextKey(aid='0', cid='BioASQ_1', vid=0, qid=None)]\n",
      "Tardive dyskinesia (TD) is a movement disorder characterized by abnormal involuntary facial movements induced by chronic therapy with classical antipsychotic medications. Currently, there is no satisfactory pharmacotherapy for TD, which represents a major limitation to therapy with classical antipsychotics. In order to develop or optimize therapies for TD, and to develop new APDs with lower indices of motor side effects, the pathology underlying TD must first be understood. The use of animal models has been used to further this objective. Here, we review different preparations that have been used to model TD and discuss the contribution of neuroimaging studies conducted in these models. Studies in animal models have lead to several hypotheses of TD pathology, although none has yet emerged as the ultimate underlying cause of this syndrome. We discuss alterations in functional indices, neuron and synapse morphology and changes in specific neurotransmitter systems that have been described in animal models of TD, and outline how these findings have contributed to our understanding of antipsychotic-induced dyskinesias. We conclude that several non-mutually exclusive theories of TD are supported by animal studies, including increases in oxidative stress leading to structural and functional changes in specific neurotransmitter systems. Elucidating the mechanisms underlying TD neuropathology partly through the use of animal models will lead to the development of APDs with superior side effect profiles or more effective therapies for TD.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 3/12 [00:02<00:06,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "If you are a traditional traveller who believes cameras are irreplaceable,here are some things you should pay attention to when looking for the perfect camera. Sensor size Along with the megapixel count,the size of the sensor dictates the general image quality as well as the camera's performance in low light. It also determines whether the camera can electronically put the details it captures bigger enough to see--which is what makes the pictures not clear enough to see when you view the photos on a bigger screen. Portability \"The important thing is that the camera isn't too big or heavy,and that you have a good zoom range for both wide-angle and telephoto shots ,\"Atherton told CNN.A good choice would be a slim,light pocket camera with a high-qualified built-in optical zoom. \"These are very popular for travel as they are light,but built with a telephoto lens that can zoom up to 60 times,\" Atherton said. Zoom and shutter speed For action or crowd shots,a fast shutter speed is a key factor. \"When dealing with anything that's active--wildlife or people in action on the street--faces change within a tiny part of a second,\" said Arnold,\"a fast shutter speed is helpful in shooting the several hundred photos you might need to get that single winning shot.\"\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'fast shutter speed', 'qid': 'tmp', 'best_span_logit': 6.2657575607299805, 'char_offsets': [1234, 1252]}}\n",
      "fast shutter speed 234 237 [Context] [ContextKey(aid='0', cid='RACE_0', vid=0, qid=None)]\n",
      "If you are a traditional traveller who believes cameras are irreplaceable,here are some things you should pay attention to when looking for the perfect camera. Sensor size Along with the megapixel count,the size of the sensor dictates the general image quality as well as the camera's performance in low light. It also determines whether the camera can electronically put the details it captures bigger enough to see--which is what makes the pictures not clear enough to see when you view the photos on a bigger screen. Portability \"The important thing is that the camera isn't too big or heavy,and that you have a good zoom range for both wide-angle and telephoto shots ,\"Atherton told CNN.A good choice would be a slim,light pocket camera with a high-qualified built-in optical zoom. \"These are very popular for travel as they are light,but built with a telephoto lens that can zoom up to 60 times,\" Atherton said. Zoom and shutter speed For action or crowd shots,a fast shutter speed is a key factor. \"When dealing with anything that's active--wildlife or people in action on the street--faces change within a tiny part of a second,\" said Arnold,\"a fast shutter speed is helpful in shooting the several hundred photos you might need to get that single winning shot.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 4/12 [00:02<00:05,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "My grandmother seems to be wrong when she says that good manners will never go out of style. Several days ago, I tried entering a lift with one of my arms fixed in a bandage while carrying a computer bag in the other. Not being fast enough, I was passed by two young people who managed to get into the lift before me. The lift door closed only after I entered. Having already pressed their wanted floor button, the young people waited impatiently for me to press the button for where I was going. If they had decided to help, we could have moved much faster. But they had not. So I did my best and pressed the button with my arm. The two young people looked very angry with me. I was losing heart. The memory of this incident has stayed with me because it followed shortly after my building's watchman refused to help me carry a heavy box full of books. His answer was that he could not carry the books a few meters because it was not his job. However, I remembered myself helping people for so many years carrying boxes, shopping bags, or pushing wheelchairs upon the request of a stranger in need or when my conscience called on me. \"Oh, this young generation, they have no manners, \"my grandmother would say. The idea of good manners refers to the considering of other people's feelings. We need more and more people to have good manners. Good manners should be-come part of our lives.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'very angry', 'qid': 'tmp', 'best_span_logit': 4.4538493156433105, 'char_offsets': [734, 744]}}\n",
      "very angry 139 141 [Context] [ContextKey(aid='0', cid='RACE_1', vid=0, qid=None)]\n",
      "My grandmother seems to be wrong when she says that good manners will never go out of style. Several days ago, I tried entering a lift with one of my arms fixed in a bandage while carrying a computer bag in the other. Not being fast enough, I was passed by two young people who managed to get into the lift before me. The lift door closed only after I entered. Having already pressed their wanted floor button, the young people waited impatiently for me to press the button for where I was going. If they had decided to help, we could have moved much faster. But they had not. So I did my best and pressed the button with my arm. The two young people looked very angry with me. I was losing heart. The memory of this incident has stayed with me because it followed shortly after my building's watchman refused to help me carry a heavy box full of books. His answer was that he could not carry the books a few meters because it was not his job. However, I remembered myself helping people for so many years carrying boxes, shopping bags, or pushing wheelchairs upon the request of a stranger in need or when my conscience called on me. \"Oh, this young generation, they have no manners, \"my grandmother would say. The idea of good manners refers to the considering of other people's feelings. We need more and more people to have good manners. Good manners should be-come part of our lives.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 5/12 [00:03<00:04,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 49ers featured one of the best running games in the NFL in 1976 NFL season. Delvin Williams emerged as an elite back, gaining over 1,200 yards rushing and made the Pro Bowl. Wilbur Jackson also enjoyed a resurgence, rushing for 792 yards. Once again Gene Washington was the teams leading receiver with 457 yards receiving and six scores. The 49ers started the season 6–1 for their best start since 1970. Most of the wins were against second-tier teams, although the 49ers did shut out the Rams 16–0, in 1976 Los Angeles Rams season on Monday Night Football. In that game the 49ers recorded 10 sacks, including 6 by Tommy Hart. However, the 49ers lost four games in a row, including two against divisional rivals Los Angeles and 1976 Atlanta Falcons season that proved fatal to their playoff hopes. Louis G. Spadia retired from the 49ers in 1977 upon the teams sale to the DeBartolo Family. The team was sold to Edward J. DeBartolo Jr. in March 1977, and despite finishing the season with a winning record of 8–6, Clark was fired after just one season by newly hired general manager Joe Thomas (American football executive), who oversaw the worst stretch of football in the teams history.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': '49ers', 'qid': 'tmp', 'best_span_logit': 6.958358287811279, 'char_offsets': [50, 55]}}\n",
      "49ers 1 2 [Context] [ContextKey(aid='0', cid='DROP_0', vid=0, qid=None)]\n",
      "The 49ers featured one of the best running games in the NFL in 1976 NFL season. Delvin Williams emerged as an elite back, gaining over 1,200 yards rushing and made the Pro Bowl. Wilbur Jackson also enjoyed a resurgence, rushing for 792 yards. Once again Gene Washington was the teams leading receiver with 457 yards receiving and six scores. The 49ers started the season 6–1 for their best start since 1970. Most of the wins were against second-tier teams, although the 49ers did shut out the Rams 16–0, in 1976 Los Angeles Rams season on Monday Night Football. In that game the 49ers recorded 10 sacks, including 6 by Tommy Hart. However, the 49ers lost four games in a row, including two against divisional rivals Los Angeles and 1976 Atlanta Falcons season that proved fatal to their playoff hopes. Louis G. Spadia retired from the 49ers in 1977 upon the teams sale to the DeBartolo Family. The team was sold to Edward J. DeBartolo Jr. in March 1977, and despite finishing the season with a winning record of 8–6, Clark was fired after just one season by newly hired general manager Joe Thomas (American football executive), who oversaw the worst stretch of football in the teams history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 6/12 [00:03<00:03,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The 49ers featured one of the best running games in the NFL in 1976 NFL season. Delvin Williams emerged as an elite back, gaining over 1,200 yards rushing and made the Pro Bowl. Wilbur Jackson also enjoyed a resurgence, rushing for 792 yards. Once again Gene Washington was the teams leading receiver with 457 yards receiving and six scores. The 49ers started the season 6–1 for their best start since 1970. Most of the wins were against second-tier teams, although the 49ers did shut out the Rams 16–0, in 1976 Los Angeles Rams season on Monday Night Football. In that game the 49ers recorded 10 sacks, including 6 by Tommy Hart. However, the 49ers lost four games in a row, including two against divisional rivals Los Angeles and 1976 Atlanta Falcons season that proved fatal to their playoff hopes. Louis G. Spadia retired from the 49ers in 1977 upon the teams sale to the DeBartolo Family. The team was sold to Edward J. DeBartolo Jr. in March 1977, and despite finishing the season with a winning record of 8–6, Clark was fired after just one season by newly hired general manager Joe Thomas (American football executive), who oversaw the worst stretch of football in the teams history.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'March', 'qid': 'tmp', 'best_span_logit': 12.267210006713867, 'char_offsets': [1004, 1009]}}\n",
      "March 184 185 [Context] [ContextKey(aid='0', cid='DROP_0', vid=0, qid=None)]\n",
      "The 49ers featured one of the best running games in the NFL in 1976 NFL season. Delvin Williams emerged as an elite back, gaining over 1,200 yards rushing and made the Pro Bowl. Wilbur Jackson also enjoyed a resurgence, rushing for 792 yards. Once again Gene Washington was the teams leading receiver with 457 yards receiving and six scores. The 49ers started the season 6–1 for their best start since 1970. Most of the wins were against second-tier teams, although the 49ers did shut out the Rams 16–0, in 1976 Los Angeles Rams season on Monday Night Football. In that game the 49ers recorded 10 sacks, including 6 by Tommy Hart. However, the 49ers lost four games in a row, including two against divisional rivals Los Angeles and 1976 Atlanta Falcons season that proved fatal to their playoff hopes. Louis G. Spadia retired from the 49ers in 1977 upon the teams sale to the DeBartolo Family. The team was sold to Edward J. DeBartolo Jr. in March 1977, and despite finishing the season with a winning record of 8–6, Clark was fired after just one season by newly hired general manager Joe Thomas (American football executive), who oversaw the worst stretch of football in the teams history.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 7/12 [00:05<00:04,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both you and the speck of dust consist of atoms of matter. So does the ground beneath your feet. In fact, everything you can see and touch is made of matter. The only things that arent matter are forms of energy, such as light and sound. Although forms of energy are not matter, the air and other substances they travel through are. So what is matter? Matter is defined as anything that has mass and volume.  Mass is the amount of matter in a substance or object. Mass is commonly measured with a balance. A simple mechanical balance is shown in Figure 3.1. It allows an object to be matched with other objects of known mass. SI units for mass are the kilogram, but for smaller masses grams are often used instead.  The more matter an object contains, generally the more it weighs. However, weight is not the same thing as mass. Weight is a measure of the force of gravity pulling on an object. It is measured with a scale, like the kitchen- scale in Figure 3.2. The scale detects how forcefully objects in the pan are being pulled downward by the force of gravity. The SI unit for weight is the newton (N). The common English unit is the pound (lb). With Earths gravity, a mass of 1 kg has a weight of 9.8 N (2.2 lb). Problem Solving Problem: At Earths gravity, what is the weight in newtons of an object with a mass of 10 kg? Solution: At Earths gravity, 1 kg has a weight of 9.8 N. Therefore, 10 kg has a weight of (10  9.8 N) = 98 N. You Try It! Problem: If you have a mass of 50 kg on Earth, what is your weight in newtons? An object with more mass is pulled by gravity with greater force, so mass and weight are closely related. However, the weight of an object can change if the force of gravity changes, even while the mass of the object remains constant. Look at the photo of astronaut Edwin E. Aldrin Jr taken by fellow astronaut Neil Armstrong, the first human to walk on the moon, in Figure 3.3. An astronaut weighed less on the moon than he did on Earth because the moons gravity is weaker than Earths. The astronauts mass, on the other hand, did not change. He still contained the same amount of matter on the moon as he did on Earth. The amount of space matter takes up is its volume. How the volume of matter is measured depends on its state. The volume of liquids is measured with measuring containers. In the kitchen, liquid volume is usually measured with measuring cups or spoons. In the lab, liquid volume is measured with containers such as graduated cylinders. Units in the metric system for liquid volume include liters (L) and milliliters (mL). The volume of gases depends on the volume of their container. Thats because gases expand to fill whatever space is available to them. For example, as you drink water from a bottle, air rushes in to take the place of the water. An \"empty\" liter bottle actually holds a liter of air. How could you find the volume of air in an \"empty\" room? The volume of regularly shaped solids can be calculated from their dimensions. For example, the volume of a rectangular solid is the product of its length, width, and height (l  w  h). For solids that have irregular shapes, the displacement method is used to measure volume. You can see how it works in Figure 3.4 and in the video below. The SI unit for solid volumes is cubic meters (m3 ). However, cubic centimeters (cm3 ) are often used for smaller volume measurements.  Matter has many properties. Some are physical properties. Physical properties of matter are properties that can be measured or observed without matter changing to a different substance. For example, whether a given substance normally exists as a solid, liquid, or gas is a physical property. Consider water. It is a liquid at room temperature, but if it freezes and \n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'energy', 'qid': 'tmp', 'best_span_logit': 6.393219470977783, 'char_offsets': [250, 256]}}\n",
      "energy 45 46 [Context] [ContextKey(aid='0', cid='TextbookQA_0', vid=0, qid=None)]\n",
      "Both you and the speck of dust consist of atoms of matter. So does the ground beneath your feet. In fact, everything you can see and touch is made of matter. The only things that arent matter are forms of energy, such as light and sound. Although forms of energy are not matter, the air and other substances they travel through are. So what is matter? Matter is defined as anything that has mass and volume.  Mass is the amount of matter in a substance or object. Mass is commonly measured with a balance. A simple mechanical balance is shown in Figure 3.1. It allows an object to be matched with other objects of known mass. SI units for mass are the kilogram, but for smaller masses grams are often used instead.  The more matter an object contains, generally the more it weighs. However, weight is not the same thing as mass. Weight is a measure of the force of gravity pulling on an object. It is measured with a scale, like the kitchen- scale in Figure 3.2. The scale detects how forcefully objects in the pan are being pulled downward by the force of gravity. The SI unit for weight is the newton (N). The common English unit is the pound (lb). With Earths gravity, a mass of 1 kg has a weight of 9.8 N (2.2 lb). Problem Solving Problem: At Earths gravity, what is the weight in newtons of an object with a mass of 10 kg? Solution: At Earths gravity, 1 kg has a weight of 9.8 N. Therefore, 10 kg has a weight of (10  9.8 N) = 98 N. You Try It! Problem: If you have a mass of 50 kg on Earth, what is your weight in newtons? An object with more mass is pulled by gravity with greater force, so mass and weight are closely related. However, the weight of an object can change if the force of gravity changes, even while the mass of the object remains constant. Look at the photo of astronaut Edwin E. Aldrin Jr taken by fellow astronaut Neil Armstrong, the first human to walk on the moon, in Figure 3.3. An astronaut weighed less on the moon than he did on Earth because the moons gravity is weaker than Earths. The astronauts mass, on the other hand, did not change. He still contained the same amount of matter on the moon as he did on Earth. The amount of space matter takes up is its volume. How the volume of matter is measured depends on its state. The volume of liquids is measured with measuring containers. In the kitchen, liquid volume is usually measured with measuring cups or spoons. In the lab, liquid volume is measured with containers such as graduated cylinders. Units in the metric system for liquid volume include liters (L) and milliliters (mL). The volume of gases depends on the volume of their container. Thats because gases expand to fill whatever space is available to them. For example, as you drink water from a bottle, air rushes in to take the place of the water. An \"empty\" liter bottle actually holds a liter of air. How could you find the volume of air in an \"empty\" room? The volume of regularly shaped solids can be calculated from their dimensions. For example, the volume of a rectangular solid is the product of its length, width, and height (l  w  h). For solids that have irregular shapes, the displacement method is used to measure volume. You can see how it works in Figure 3.4 and in the video below. The SI unit for solid volumes is cubic meters (m3 ). However, cubic centimeters (cm3 ) are often used for smaller volume measurements.  Matter has many properties. Some are physical properties. Physical properties of matter are properties that can be measured or observed without matter changing to a different substance. For example, whether a given substance normally exists as a solid, liquid, or gas is a physical property. Consider water. It is a liquid at room temperature, but if it freezes and \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 9/12 [00:06<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Both you and the speck of dust consist of atoms of matter. So does the ground beneath your feet. In fact, everything you can see and touch is made of matter. The only things that arent matter are forms of energy, such as light and sound. Although forms of energy are not matter, the air and other substances they travel through are. So what is matter? Matter is defined as anything that has mass and volume.  Mass is the amount of matter in a substance or object. Mass is commonly measured with a balance. A simple mechanical balance is shown in Figure 3.1. It allows an object to be matched with other objects of known mass. SI units for mass are the kilogram, but for smaller masses grams are often used instead.  The more matter an object contains, generally the more it weighs. However, weight is not the same thing as mass. Weight is a measure of the force of gravity pulling on an object. It is measured with a scale, like the kitchen- scale in Figure 3.2. The scale detects how forcefully objects in the pan are being pulled downward by the force of gravity. The SI unit for weight is the newton (N). The common English unit is the pound (lb). With Earths gravity, a mass of 1 kg has a weight of 9.8 N (2.2 lb). Problem Solving Problem: At Earths gravity, what is the weight in newtons of an object with a mass of 10 kg? Solution: At Earths gravity, 1 kg has a weight of 9.8 N. Therefore, 10 kg has a weight of (10  9.8 N) = 98 N. You Try It! Problem: If you have a mass of 50 kg on Earth, what is your weight in newtons? An object with more mass is pulled by gravity with greater force, so mass and weight are closely related. However, the weight of an object can change if the force of gravity changes, even while the mass of the object remains constant. Look at the photo of astronaut Edwin E. Aldrin Jr taken by fellow astronaut Neil Armstrong, the first human to walk on the moon, in Figure 3.3. An astronaut weighed less on the moon than he did on Earth because the moons gravity is weaker than Earths. The astronauts mass, on the other hand, did not change. He still contained the same amount of matter on the moon as he did on Earth. The amount of space matter takes up is its volume. How the volume of matter is measured depends on its state. The volume of liquids is measured with measuring containers. In the kitchen, liquid volume is usually measured with measuring cups or spoons. In the lab, liquid volume is measured with containers such as graduated cylinders. Units in the metric system for liquid volume include liters (L) and milliliters (mL). The volume of gases depends on the volume of their container. Thats because gases expand to fill whatever space is available to them. For example, as you drink water from a bottle, air rushes in to take the place of the water. An \"empty\" liter bottle actually holds a liter of air. How could you find the volume of air in an \"empty\" room? The volume of regularly shaped solids can be calculated from their dimensions. For example, the volume of a rectangular solid is the product of its length, width, and height (l  w  h). For solids that have irregular shapes, the displacement method is used to measure volume. You can see how it works in Figure 3.4 and in the video below. The SI unit for solid volumes is cubic meters (m3 ). However, cubic centimeters (cm3 ) are often used for smaller volume measurements.  Matter has many properties. Some are physical properties. Physical properties of matter are properties that can be measured or observed without matter changing to a different substance. For example, whether a given substance normally exists as a solid, liquid, or gas is a physical property. Consider water. It is a liquid at room temperature, but if it freezes and \n",
      "{'tmp': {'loss': 0.0, 'best_span_str': ' ', 'qid': 'tmp', 'best_span_logit': 0.6220135688781738, 'char_offsets': [449, 450]}}\n",
      "  87 88 [Context] [ContextKey(aid='0', cid='TextbookQA_1', vid=0, qid=None)]\n",
      "Both you and the speck of dust consist of atoms of matter. So does the ground beneath your feet. In fact, everything you can see and touch is made of matter. The only things that arent matter are forms of energy, such as light and sound. Although forms of energy are not matter, the air and other substances they travel through are. So what is matter? Matter is defined as anything that has mass and volume.  Mass is the amount of matter in a substance or object. Mass is commonly measured with a balance. A simple mechanical balance is shown in Figure 3.1. It allows an object to be matched with other objects of known mass. SI units for mass are the kilogram, but for smaller masses grams are often used instead.  The more matter an object contains, generally the more it weighs. However, weight is not the same thing as mass. Weight is a measure of the force of gravity pulling on an object. It is measured with a scale, like the kitchen- scale in Figure 3.2. The scale detects how forcefully objects in the pan are being pulled downward by the force of gravity. The SI unit for weight is the newton (N). The common English unit is the pound (lb). With Earths gravity, a mass of 1 kg has a weight of 9.8 N (2.2 lb). Problem Solving Problem: At Earths gravity, what is the weight in newtons of an object with a mass of 10 kg? Solution: At Earths gravity, 1 kg has a weight of 9.8 N. Therefore, 10 kg has a weight of (10  9.8 N) = 98 N. You Try It! Problem: If you have a mass of 50 kg on Earth, what is your weight in newtons? An object with more mass is pulled by gravity with greater force, so mass and weight are closely related. However, the weight of an object can change if the force of gravity changes, even while the mass of the object remains constant. Look at the photo of astronaut Edwin E. Aldrin Jr taken by fellow astronaut Neil Armstrong, the first human to walk on the moon, in Figure 3.3. An astronaut weighed less on the moon than he did on Earth because the moons gravity is weaker than Earths. The astronauts mass, on the other hand, did not change. He still contained the same amount of matter on the moon as he did on Earth. The amount of space matter takes up is its volume. How the volume of matter is measured depends on its state. The volume of liquids is measured with measuring containers. In the kitchen, liquid volume is usually measured with measuring cups or spoons. In the lab, liquid volume is measured with containers such as graduated cylinders. Units in the metric system for liquid volume include liters (L) and milliliters (mL). The volume of gases depends on the volume of their container. Thats because gases expand to fill whatever space is available to them. For example, as you drink water from a bottle, air rushes in to take the place of the water. An \"empty\" liter bottle actually holds a liter of air. How could you find the volume of air in an \"empty\" room? The volume of regularly shaped solids can be calculated from their dimensions. For example, the volume of a rectangular solid is the product of its length, width, and height (l  w  h). For solids that have irregular shapes, the displacement method is used to measure volume. You can see how it works in Figure 3.4 and in the video below. The SI unit for solid volumes is cubic meters (m3 ). However, cubic centimeters (cm3 ) are often used for smaller volume measurements.  Matter has many properties. Some are physical properties. Physical properties of matter are properties that can be measured or observed without matter changing to a different substance. For example, whether a given substance normally exists as a solid, liquid, or gas is a physical property. Consider water. It is a liquid at room temperature, but if it freezes and \n",
      "\n",
      "Ray Eberle died of a heart attack in Douglasville, Georgia on August 25, 1979, aged 60.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'heart attack', 'qid': 'tmp', 'best_span_logit': 9.01836109161377, 'char_offsets': [51, 63]}}\n",
      "heart attack 5 7 [Context] [ContextKey(aid='0', cid='RelationExtraction_0', vid=0, qid=None)]\n",
      "Ray Eberle died of a heart attack in Douglasville, Georgia on August 25, 1979, aged 60.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 10/12 [00:06<00:01,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extremaduran Popular Bloc (Spanish: Bloque Popular de Extremadura, BPEx) was a communist political coalition created in Extremadura in 1981 and dissolved in 1983.\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': '1983', 'qid': 'tmp', 'best_span_logit': 13.758576393127441, 'char_offsets': [215, 219]}}\n",
      "1983 26 27 [Context] [ContextKey(aid='0', cid='RelationExtraction_1', vid=0, qid=None)]\n",
      "Extremaduran Popular Bloc (Spanish: Bloque Popular de Extremadura, BPEx) was a communist political coalition created in Extremadura in 1981 and dissolved in 1983.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 11/12 [00:08<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "New Orleans, Louisiana, 1927. An enraged posse of men descend on the isolated Seven Doors Hotel deep in the swamps. They grab an artist called Schweik (Antoine Saint John), who is cloistered there. Accusing him of being a warlock, Schweik is dragged down to the cellar where he is savagely beaten with heavy chains, tortured with quicklime acid, and crucified with his wrists nailed to a cellar wall, despite his dire warnings of evil to be unleashed.New Orleans, 1981. Liza Merril (Catriona MacColl) is a young woman who arrives from New York City to claim the hotel as her inheritance. No sooner has architect friend Marin Avery (Michele Mirabella) begins to show her around the property, strange incidents begin to happen. A painter (Anthony Flees) falls off his rig and is horribly injured, coughing up blood and babbling about, \"the eyes, the eyes.\" Dr. John McCabe (David Warbeck) arrives to take the injured man to the hospital, and offers Liza some sympathy. Next, a plumber, named Joe, attempts to repair a major leak in the flooded cellar. However, he is murdered by a presence that emerged from behind a slim-caked wall. The atmosphere at the hotel is further chilled by the creepy-looking servants, Arthur (Giampaolo Saccarola) and Martha (Veronica Lazar), who apparently come with the hotel. Martha discovers Joe's dead body in the cellar, and another much older cadaver lying in a pool of dirty water nearby. It is apparently that of Schweik, the artist.Driving down the 14-mile causeway to New Orleans, Liza encounters a strange blind woman, standing in the middle of the desolate highway. The blind woman introduces herself as Emily (Sarah Keller), and tells Liza that she has been waiting for her, although her eyes are occluded with cataracts. Liza drives Emily over to her opulently furnished house in New Orleans. Liza is warned by Emily to leave the hotel while she still can. Meanwhile at the hospital morgue, Dr. John McCabe is performing the autopsy on Joe the plumber while his assistant Harris (Al Cliver) wants to install an EMG machine to the corpse of Schweik. John laughs it off and leaves for lunch, while Harris remains behind to install the EMG machine. After Harris leaves for a call, the EMG machine begins pulsing with activity. A little later, Joe's wife Mary-Anne (Laura De Marchi) arrives with her daughter Jill (Maria Pia Marsale) to dress up her husband's corpse for the funeral, when she is killed in a horrific way by scalded with acid. Jill is then menaced by the re-animated cadaver of Schweik.Liza meets with John McCabe in a downtown bar to discuss her misgivings and anxieties. He expresses puzzlement when Lisa complains about he ineptitude of her weird servants. John claims to have never heard of them before despite knowing everyone in the area. Then a phone call from the bar arrives from Harris who informs John that Mary-Anne's body was found in the morgue, while Jill was found huddled in a corner frightened and unable to speak. After Joe and Mary-Anne's funeral, Emily appears again to Liza that evening at the hotel. Emily tells Liza about the warlock Schweik, who stayed in Room 36 of the hotel and about the supernatural underworld that the hotel conceals. The hotel was built over one of the Seven Gates of Hell, and Schweik has been the Guardian. Emily is about to reveal more when her hands wander over to a canvas depicting a desolate vision of lost souls in a terrible and arid landscape. Suddenly afraid, Emily says that the painting was painted by Schweik before he died, and she runs out of the hotel parlor into the night. But Liza notices a disquieting fact about her sudden departure: Emily made no footfalls on the bare wooden boards as she ran, and neither did her seeing-eye dog.The next day, Liza ventures nervously into Room 36, a dingy phantasmal of sheet-covered furniture and shafts of dusty light. She finds an ancient book, whose weirdly flesh-like cover bears the single word\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': 'quicklime acid', 'qid': 'tmp', 'best_span_logit': 6.773420333862305, 'char_offsets': [379, 393]}}\n",
      "quicklime acid 67 69 [Context] [ContextKey(aid='0', cid='DuoRC.ParaphraseRC_0', vid=0, qid=None)]\n",
      "\n",
      "\n",
      "New Orleans, Louisiana, 1927. An enraged posse of men descend on the isolated Seven Doors Hotel deep in the swamps. They grab an artist called Schweik (Antoine Saint John), who is cloistered there. Accusing him of being a warlock, Schweik is dragged down to the cellar where he is savagely beaten with heavy chains, tortured with quicklime acid, and crucified with his wrists nailed to a cellar wall, despite his dire warnings of evil to be unleashed.New Orleans, 1981. Liza Merril (Catriona MacColl) is a young woman who arrives from New York City to claim the hotel as her inheritance. No sooner has architect friend Marin Avery (Michele Mirabella) begins to show her around the property, strange incidents begin to happen. A painter (Anthony Flees) falls off his rig and is horribly injured, coughing up blood and babbling about, \"the eyes, the eyes.\" Dr. John McCabe (David Warbeck) arrives to take the injured man to the hospital, and offers Liza some sympathy. Next, a plumber, named Joe, attempts to repair a major leak in the flooded cellar. However, he is murdered by a presence that emerged from behind a slim-caked wall. The atmosphere at the hotel is further chilled by the creepy-looking servants, Arthur (Giampaolo Saccarola) and Martha (Veronica Lazar), who apparently come with the hotel. Martha discovers Joe's dead body in the cellar, and another much older cadaver lying in a pool of dirty water nearby. It is apparently that of Schweik, the artist.Driving down the 14-mile causeway to New Orleans, Liza encounters a strange blind woman, standing in the middle of the desolate highway. The blind woman introduces herself as Emily (Sarah Keller), and tells Liza that she has been waiting for her, although her eyes are occluded with cataracts. Liza drives Emily over to her opulently furnished house in New Orleans. Liza is warned by Emily to leave the hotel while she still can. Meanwhile at the hospital morgue, Dr. John McCabe is performing the autopsy on Joe the plumber while his assistant Harris (Al Cliver) wants to install an EMG machine to the corpse of Schweik. John laughs it off and leaves for lunch, while Harris remains behind to install the EMG machine. After Harris leaves for a call, the EMG machine begins pulsing with activity. A little later, Joe's wife Mary-Anne (Laura De Marchi) arrives with her daughter Jill (Maria Pia Marsale) to dress up her husband's corpse for the funeral, when she is killed in a horrific way by scalded with acid. Jill is then menaced by the re-animated cadaver of Schweik.Liza meets with John McCabe in a downtown bar to discuss her misgivings and anxieties. He expresses puzzlement when Lisa complains about he ineptitude of her weird servants. John claims to have never heard of them before despite knowing everyone in the area. Then a phone call from the bar arrives from Harris who informs John that Mary-Anne's body was found in the morgue, while Jill was found huddled in a corner frightened and unable to speak. After Joe and Mary-Anne's funeral, Emily appears again to Liza that evening at the hotel. Emily tells Liza about the warlock Schweik, who stayed in Room 36 of the hotel and about the supernatural underworld that the hotel conceals. The hotel was built over one of the Seven Gates of Hell, and Schweik has been the Guardian. Emily is about to reveal more when her hands wander over to a canvas depicting a desolate vision of lost souls in a terrible and arid landscape. Suddenly afraid, Emily says that the painting was painted by Schweik before he died, and she runs out of the hotel parlor into the night. But Liza notices a disquieting fact about her sudden departure: Emily made no footfalls on the bare wooden boards as she ran, and neither did her seeing-eye dog.The next day, Liza ventures nervously into Room 36, a dingy phantasmal of sheet-covered furniture and shafts of dusty light. She finds an ancient book, whose weirdly flesh-like cover bears the single word\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:09<00:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "New Orleans, Louisiana, 1927. An enraged posse of men descend on the isolated Seven Doors Hotel deep in the swamps. They grab an artist called Schweik (Antoine Saint John), who is cloistered there. Accusing him of being a warlock, Schweik is dragged down to the cellar where he is savagely beaten with heavy chains, tortured with quicklime acid, and crucified with his wrists nailed to a cellar wall, despite his dire warnings of evil to be unleashed.New Orleans, 1981. Liza Merril (Catriona MacColl) is a young woman who arrives from New York City to claim the hotel as her inheritance. No sooner has architect friend Marin Avery (Michele Mirabella) begins to show her around the property, strange incidents begin to happen. A painter (Anthony Flees) falls off his rig and is horribly injured, coughing up blood and babbling about, \"the eyes, the eyes.\" Dr. John McCabe (David Warbeck) arrives to take the injured man to the hospital, and offers Liza some sympathy. Next, a plumber, named Joe, attempts to repair a major leak in the flooded cellar. However, he is murdered by a presence that emerged from behind a slim-caked wall. The atmosphere at the hotel is further chilled by the creepy-looking servants, Arthur (Giampaolo Saccarola) and Martha (Veronica Lazar), who apparently come with the hotel. Martha discovers Joe's dead body in the cellar, and another much older cadaver lying in a pool of dirty water nearby. It is apparently that of Schweik, the artist.Driving down the 14-mile causeway to New Orleans, Liza encounters a strange blind woman, standing in the middle of the desolate highway. The blind woman introduces herself as Emily (Sarah Keller), and tells Liza that she has been waiting for her, although her eyes are occluded with cataracts. Liza drives Emily over to her opulently furnished house in New Orleans. Liza is warned by Emily to leave the hotel while she still can. Meanwhile at the hospital morgue, Dr. John McCabe is performing the autopsy on Joe the plumber while his assistant Harris (Al Cliver) wants to install an EMG machine to the corpse of Schweik. John laughs it off and leaves for lunch, while Harris remains behind to install the EMG machine. After Harris leaves for a call, the EMG machine begins pulsing with activity. A little later, Joe's wife Mary-Anne (Laura De Marchi) arrives with her daughter Jill (Maria Pia Marsale) to dress up her husband's corpse for the funeral, when she is killed in a horrific way by scalded with acid. Jill is then menaced by the re-animated cadaver of Schweik.Liza meets with John McCabe in a downtown bar to discuss her misgivings and anxieties. He expresses puzzlement when Lisa complains about he ineptitude of her weird servants. John claims to have never heard of them before despite knowing everyone in the area. Then a phone call from the bar arrives from Harris who informs John that Mary-Anne's body was found in the morgue, while Jill was found huddled in a corner frightened and unable to speak. After Joe and Mary-Anne's funeral, Emily appears again to Liza that evening at the hotel. Emily tells Liza about the warlock Schweik, who stayed in Room 36 of the hotel and about the supernatural underworld that the hotel conceals. The hotel was built over one of the Seven Gates of Hell, and Schweik has been the Guardian. Emily is about to reveal more when her hands wander over to a canvas depicting a desolate vision of lost souls in a terrible and arid landscape. Suddenly afraid, Emily says that the painting was painted by Schweik before he died, and she runs out of the hotel parlor into the night. But Liza notices a disquieting fact about her sudden departure: Emily made no footfalls on the bare wooden boards as she ran, and neither did her seeing-eye dog.The next day, Liza ventures nervously into Room 36, a dingy phantasmal of sheet-covered furniture and shafts of dusty light. She finds an ancient book, whose weirdly flesh-like cover bears the single word\n",
      "{'tmp': {'loss': 0.0, 'best_span_str': '1927', 'qid': 'tmp', 'best_span_logit': 10.25151538848877, 'char_offsets': [107, 111]}}\n",
      "1927 6 7 [Context] [ContextKey(aid='0', cid='DuoRC.ParaphraseRC_0', vid=0, qid=None)]\n",
      "\n",
      "\n",
      "New Orleans, Louisiana, 1927. An enraged posse of men descend on the isolated Seven Doors Hotel deep in the swamps. They grab an artist called Schweik (Antoine Saint John), who is cloistered there. Accusing him of being a warlock, Schweik is dragged down to the cellar where he is savagely beaten with heavy chains, tortured with quicklime acid, and crucified with his wrists nailed to a cellar wall, despite his dire warnings of evil to be unleashed.New Orleans, 1981. Liza Merril (Catriona MacColl) is a young woman who arrives from New York City to claim the hotel as her inheritance. No sooner has architect friend Marin Avery (Michele Mirabella) begins to show her around the property, strange incidents begin to happen. A painter (Anthony Flees) falls off his rig and is horribly injured, coughing up blood and babbling about, \"the eyes, the eyes.\" Dr. John McCabe (David Warbeck) arrives to take the injured man to the hospital, and offers Liza some sympathy. Next, a plumber, named Joe, attempts to repair a major leak in the flooded cellar. However, he is murdered by a presence that emerged from behind a slim-caked wall. The atmosphere at the hotel is further chilled by the creepy-looking servants, Arthur (Giampaolo Saccarola) and Martha (Veronica Lazar), who apparently come with the hotel. Martha discovers Joe's dead body in the cellar, and another much older cadaver lying in a pool of dirty water nearby. It is apparently that of Schweik, the artist.Driving down the 14-mile causeway to New Orleans, Liza encounters a strange blind woman, standing in the middle of the desolate highway. The blind woman introduces herself as Emily (Sarah Keller), and tells Liza that she has been waiting for her, although her eyes are occluded with cataracts. Liza drives Emily over to her opulently furnished house in New Orleans. Liza is warned by Emily to leave the hotel while she still can. Meanwhile at the hospital morgue, Dr. John McCabe is performing the autopsy on Joe the plumber while his assistant Harris (Al Cliver) wants to install an EMG machine to the corpse of Schweik. John laughs it off and leaves for lunch, while Harris remains behind to install the EMG machine. After Harris leaves for a call, the EMG machine begins pulsing with activity. A little later, Joe's wife Mary-Anne (Laura De Marchi) arrives with her daughter Jill (Maria Pia Marsale) to dress up her husband's corpse for the funeral, when she is killed in a horrific way by scalded with acid. Jill is then menaced by the re-animated cadaver of Schweik.Liza meets with John McCabe in a downtown bar to discuss her misgivings and anxieties. He expresses puzzlement when Lisa complains about he ineptitude of her weird servants. John claims to have never heard of them before despite knowing everyone in the area. Then a phone call from the bar arrives from Harris who informs John that Mary-Anne's body was found in the morgue, while Jill was found huddled in a corner frightened and unable to speak. After Joe and Mary-Anne's funeral, Emily appears again to Liza that evening at the hotel. Emily tells Liza about the warlock Schweik, who stayed in Room 36 of the hotel and about the supernatural underworld that the hotel conceals. The hotel was built over one of the Seven Gates of Hell, and Schweik has been the Guardian. Emily is about to reveal more when her hands wander over to a canvas depicting a desolate vision of lost souls in a terrible and arid landscape. Suddenly afraid, Emily says that the painting was painted by Schweik before he died, and she runs out of the hotel parlor into the night. But Liza notices a disquieting fact about her sudden departure: Emily made no footfalls on the bare wooden boards as she ran, and neither did her seeing-eye dog.The next day, Liza ventures nervously into Room 36, a dingy phantasmal of sheet-covered furniture and shafts of dusty light. She finds an ancient book, whose weirdly flesh-like cover bears the single word\n",
      "         f1  predictor\n",
      "0  0.665873  mrqa_path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({InstanceKey(qid='2cf03749226444fea30c672c678b3d63', vid=0): Instance [InstanceKey(qid='2cf03749226444fea30c672c678b3d63', vid=0)],\n",
       "  InstanceKey(qid='b0f3562cb2574620ba46ae33c88d65b3', vid=0): Instance [InstanceKey(qid='b0f3562cb2574620ba46ae33c88d65b3', vid=0)],\n",
       "  InstanceKey(qid='b972e2ba473a4974bc7573f4de739abc', vid=0): Instance [InstanceKey(qid='b972e2ba473a4974bc7573f4de739abc', vid=0)],\n",
       "  InstanceKey(qid='0f52ba11790d4329a176dab862cf963d', vid=0): Instance [InstanceKey(qid='0f52ba11790d4329a176dab862cf963d', vid=0)],\n",
       "  InstanceKey(qid='52f53a3df5b149b7a33f04a187a73911', vid=0): Instance [InstanceKey(qid='52f53a3df5b149b7a33f04a187a73911', vid=0)],\n",
       "  InstanceKey(qid='e50445009e7c468a8fded2a3a0cd8519', vid=0): Instance [InstanceKey(qid='e50445009e7c468a8fded2a3a0cd8519', vid=0)],\n",
       "  InstanceKey(qid='7a048da2ada24c88a29a99db34ca314e', vid=0): Instance [InstanceKey(qid='7a048da2ada24c88a29a99db34ca314e', vid=0)],\n",
       "  InstanceKey(qid='b498484bbf5344158f2830592c1525f0', vid=0): Instance [InstanceKey(qid='b498484bbf5344158f2830592c1525f0', vid=0)],\n",
       "  InstanceKey(qid='5b704e92b4d34957b69ef29110871144', vid=0): Instance [InstanceKey(qid='5b704e92b4d34957b69ef29110871144', vid=0)],\n",
       "  InstanceKey(qid='95a99efe2dc94147afdd4f6c9b3cc9a5', vid=0): Instance [InstanceKey(qid='95a99efe2dc94147afdd4f6c9b3cc9a5', vid=0)],\n",
       "  InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0): Instance [InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0)],\n",
       "  InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0): Instance [InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0)]},\n",
       " {},\n",
       " defaultdict(list,\n",
       "             {'0f52ba11790d4329a176dab862cf963d': [InstanceKey(qid='0f52ba11790d4329a176dab862cf963d', vid=0)],\n",
       "              '2cf03749226444fea30c672c678b3d63': [InstanceKey(qid='2cf03749226444fea30c672c678b3d63', vid=0)],\n",
       "              '52f53a3df5b149b7a33f04a187a73911': [InstanceKey(qid='52f53a3df5b149b7a33f04a187a73911', vid=0)],\n",
       "              '5b704e92b4d34957b69ef29110871144': [InstanceKey(qid='5b704e92b4d34957b69ef29110871144', vid=0)],\n",
       "              '7a048da2ada24c88a29a99db34ca314e': [InstanceKey(qid='7a048da2ada24c88a29a99db34ca314e', vid=0)],\n",
       "              '95a99efe2dc94147afdd4f6c9b3cc9a5': [InstanceKey(qid='95a99efe2dc94147afdd4f6c9b3cc9a5', vid=0)],\n",
       "              'b0f3562cb2574620ba46ae33c88d65b3': [InstanceKey(qid='b0f3562cb2574620ba46ae33c88d65b3', vid=0)],\n",
       "              'b498484bbf5344158f2830592c1525f0': [InstanceKey(qid='b498484bbf5344158f2830592c1525f0', vid=0)],\n",
       "              'b972e2ba473a4974bc7573f4de739abc': [InstanceKey(qid='b972e2ba473a4974bc7573f4de739abc', vid=0)],\n",
       "              'd94a42693350473581ff79dc91c91e04': [InstanceKey(qid='d94a42693350473581ff79dc91c91e04', vid=0)],\n",
       "              'e50445009e7c468a8fded2a3a0cd8519': [InstanceKey(qid='e50445009e7c468a8fded2a3a0cd8519', vid=0)],\n",
       "              'f41dbe24bed44870a8ad36c87dda59a2': [InstanceKey(qid='f41dbe24bed44870a8ad36c87dda59a2', vid=0)]}))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "predictors = { p.name: p for p in [predictor] }\n",
    "predictions = { p: [] for p in predictors }\n",
    "logger.info(\"Running predictions....\")\n",
    "for instance in tqdm(instances):\n",
    "    instance_predictions = []\n",
    "    for predictor in predictors.values():\n",
    "        prediction = Predictor.by_name(\"qa_task_class\").model_predict(\n",
    "            predictor, \n",
    "            instance.question, \n",
    "            instance.context, \n",
    "            instance.groundtruths)\n",
    "        instance_predictions.append(prediction)\n",
    "        print(prediction.doc, prediction.span_start, prediction.span_end, instance.context)\n",
    "        predictions[predictor.name].append(prediction)\n",
    "    instance.set_entries(predictions=instance_predictions)\n",
    "for predictor in predictors.values():\n",
    "    predictor.evaluate_performance(instances)\n",
    "print(pd.DataFrame([ {\"predictor\": p.name, \"f1\": p.perform[\"f1\"] } for p in predictors.values() ]))\n",
    "Instance.build_instance_hashes(instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictors' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-0c0ee2b50915>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"predictor\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"f1\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predictors' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([ {\"predictor\": p.name, \"f1\": p.perform[\"f1\"] } for p in predictors.values() ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:errudite.utils.registrable:Register mrqa as DatasetReader: Overwritting name already in use for MRQAReader.\n",
      "WARNING:errudite.utils.file_utils:Local path not yet exist, but still parsed: /Users/tongshuangwu/datasets/caches/dataset_debug/mrqa-100/vocab.pkl\n",
      "WARNING:errudite.processor.spacy_annotator:(2, 'No such file or directory')\n",
      "INFO:errudite.io.dataset_reader:Computing vocab frequency from file at: /Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/BioASQ.jsonl.gz,/Users/tongshuangwu/datasets/raw_data/mrqa/out_of_domain_devs/RACE.jsonl.gz\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "INFO:root:\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 3325, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-5-181d9ff5b766>\", line 4, in <module>\n",
      "    reader.count_vocab_freq(file_path)\n",
      "  File \"../errudite/io/dataset_reader.py\", line 124, in count_vocab_freq\n",
      "    target_dicts = self._read(file_path, lazy=True, sample_size=None)\n",
      "  File \"../errudite/io/mrqa_reader.py\", line 59, in _read\n",
      "    for cidx, example in enumerate(dataset['file_handle']):\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/gzip.py\", line 373, in readline\n",
      "    self._check_not_closed()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2039, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 319, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/tongshuangwu/sourcetree/errudite_dataset_debug/venv/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 353, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1483, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 1441, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/inspect.py\", line 733, in getmodule\n",
      "    if ismodule(module) and hasattr(module, '__file__'):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "TRAIN_DATASET_FOLDER = normalize_file_path(\"~/datasets/raw_data/mrqa/trains\")\n",
    "sample_size=100\n",
    "file_path = \",\".join(glob.glob(os.path.join(DATASET_FOLDER, \"*.jsonl.gz\"))[:2])\n",
    "reader.count_vocab_freq(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
